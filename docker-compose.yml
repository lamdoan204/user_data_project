services:
  db:
    container_name: postgres_container
    image: postgres:14.0
    ports:
      - 5000:5432
    environment:
      POSTGRES_DB: db
      POSTGRES_USER: db_user
      POSTGRES_PASSWORD: db_password
    volumes:
      - ./postgres/data:/var/lib/postgresql/data
      - ./postgres/airflow_init.sql:/docker-entrypoint-initdb.d/airflow_init.sql
    networks:
      - my-network
  airflow:
    container_name: airflow_container
    image: apache/airflow:latest
    ports:
     - 8080:8080
    environment:
      AIRFLOW_DATABASE_SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@db:5432/airflow_db
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./api-request/:/opt/airflow/api-request
      - /var/run/docker.sock:/var/run/docker.sock 
    depends_on:
      - db
    networks:
      - my-network
    command: 
     bash -c " pip install kafka-python && airflow db migrate && airflow standalone"

  kafka: 
    image: bitnami/kafka:latest
    container_name: kafka_container
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:29092
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:29092,OUTSIDE://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,OUTSIDE://localhost:9093
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,OUTSIDE:PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_CFG_GROUP_INITIAL_REBALANCE_DELAY_MS=0
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_CFG_LOG_DIRS=/tmp/kraft-combined-logs
    volumes:
      - ./kafka/data:/var/lib/kafka/data
    networks:
      - my-network
    ports:
      - 9092:9092
      - 9093:9093
  
    
  spark-master:
    container_name: spark_master
    image: bitnami/spark:3.5.0
    environment:
      - SPARK_MODE=master
    ports:
      - "7077:7077"
    volumes:
      - ./api-request/spark_consumer.py:/opt/bitnami/spark/spark_consumer.py
    networks:
      - my-network

  # Spark Worker
  spark-worker:
    image: bitnami/spark:3.5.0
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - spark-master
    networks:
      - my-network

  redpanda:
    image: docker.redpanda.com/redpandadata/console:latest
    container_name: redpanda_container
    restart: on-failure
    depends_on:
      - kafka
    environment:
      KAFKA_BROKERS: kafka:9092
    networks:
      - my-network
    ports:
      - 8081:8080
networks:
  my-network:
    driver: bridge